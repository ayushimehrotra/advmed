{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7b460b19-bc61-4bc5-a1a7-428c664029ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305c64ce-18a1-424b-9a45-edc38953af07",
   "metadata": {},
   "source": [
    "## Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10319434-4e42-41a4-9168-bffed6876b56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "!pip install torch\n",
    "!pip install torchvision\n",
    "!pip install captum\n",
    "!pip install opencv-python\n",
    "!pip install seaborn\n",
    "!pip install matplotlib\n",
    "!pip install cleverhans\n",
    "!pip install cachetools\n",
    "!pip install pandas\n",
    "!apt-get update && apt-get install ffmpeg libsm6 libxext6  -y\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5a1cdff-4a0a-41eb-ae7a-78f96dabdc9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['HAM10000_images_part_1', 'ham10000_images_part_1', 'hmnist_28_28_L.csv', 'hmnist_8_8_L.csv', 'HAM10000_metadata.csv', 'hmnist_28_28_RGB.csv', 'hmnist_8_8_RGB.csv', 'HAM10000_images_part_2', 'ham10000_images_part_2']\n"
     ]
    }
   ],
   "source": [
    "import os, cv2,itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "\n",
    "# pytorch libraries\n",
    "import torch\n",
    "from torch import optim,nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from torchvision import models,transforms\n",
    "\n",
    "# sklearn libraries\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# to make the results are reproducible\n",
    "np.random.seed(10)\n",
    "torch.manual_seed(10)\n",
    "torch.cuda.manual_seed(10)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(os.listdir(\"skin-cancer\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eba59ec7-f54d-49ae-8407-93ff29b4d6e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matplotlib.image import imread\n",
    "import seaborn as sns\n",
    "import random\n",
    "import copy\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision.utils import make_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e60f74-ef8f-4c2c-a1c5-e97bb56a68b8",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44d48e96-931b-4c0b-94db-e26544397e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'skin-cancer'\n",
    "all_image_path = glob(os.path.join(data_dir, '*', '*.jpg'))\n",
    "#extracts the image id to match it with the .csv label file\n",
    "imageid_path_dict = {os.path.splitext(os.path.basename(x))[0] : x for x in all_image_path}\n",
    "lesion_type_dict = {\n",
    "    'nv': 'Melanocytic nevi',\n",
    "    'mel': 'dermatofibroma',\n",
    "    'bkl': 'Benign keratosis-like lesions ',\n",
    "    'bcc': 'Basal cell carcinoma',\n",
    "    'akiec': 'Actinic keratoses',\n",
    "    'vasc': 'Vascular lesions',\n",
    "    'df': 'Dermatofibroma'\n",
    "}\n",
    "input_size = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f85c81e-2c6a-440f-8067-3271ab3e4f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19/4162347508.py:46: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_train=df_train.append([df_train.loc[df_train['cell_type_idx'] == i,:]]*(data_aug_rate[i]-1), ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Melanocytic nevi                  5822\n",
       "Dermatofibroma                    5350\n",
       "dermatofibroma                    5335\n",
       "Vascular lesions                  5160\n",
       "Benign keratosis-like lesions     5055\n",
       "Basal cell carcinoma              4790\n",
       "Actinic keratoses                 4455\n",
       "Name: cell_type, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_original = pd.read_csv(os.path.join(data_dir, 'HAM10000_metadata.csv'))\n",
    "df_original['path'] = df_original['image_id'].map(imageid_path_dict.get)\n",
    "df_original['cell_type'] = df_original['dx'].map(lesion_type_dict.get)\n",
    "df_original['cell_type_idx'] = pd.Categorical(df_original['cell_type']).codes\n",
    "\n",
    "df_undup = df_original.groupby('lesion_id').count()\n",
    "# now we filter out lesion_id's that have only one image associated with it\n",
    "df_undup = df_undup[df_undup['image_id'] == 1]\n",
    "df_undup.reset_index(inplace=True)\n",
    "\n",
    "def get_duplicates(x):\n",
    "    unique_list = list(df_undup['lesion_id'])\n",
    "    if x in unique_list:\n",
    "        return 'unduplicated'\n",
    "    else:\n",
    "        return 'duplicated'\n",
    "\n",
    "# create a new colum that is a copy of the lesion_id column\n",
    "df_original['duplicates'] = df_original['lesion_id']\n",
    "# apply the function to this new column\n",
    "df_original['duplicates'] = df_original['duplicates'].apply(get_duplicates)\n",
    "\n",
    "df_undup = df_original[df_original['duplicates'] == 'unduplicated']\n",
    "y = df_undup['cell_type_idx']\n",
    "_, df_val = train_test_split(df_undup, test_size=0.2, random_state=101, stratify=y)\n",
    "\n",
    "def get_val_rows(x):\n",
    "    # create a list of all the lesion_id's in the val set\n",
    "    val_list = list(df_val['image_id'])\n",
    "    if str(x) in val_list:\n",
    "        return 'val'\n",
    "    else:\n",
    "        return 'train'\n",
    "\n",
    "# identify train and val rows\n",
    "# create a new colum that is a copy of the image_id column\n",
    "df_original['train_or_val'] = df_original['image_id']\n",
    "# apply the function to this new column\n",
    "df_original['train_or_val'] = df_original['train_or_val'].apply(get_val_rows)\n",
    "# filter out train rows\n",
    "df_train = df_original[df_original['train_or_val'] == 'train']\n",
    "\n",
    "data_aug_rate = [15,10,5,50,0,40,5]\n",
    "for i in range(7):\n",
    "    if data_aug_rate[i]:\n",
    "        df_train=df_train.append([df_train.loc[df_train['cell_type_idx'] == i,:]]*(data_aug_rate[i]-1), ignore_index=True)\n",
    "df_train['cell_type'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e2cbe41-94ec-4490-9a91-bfc6f4363d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.reset_index()\n",
    "df_val = df_val.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4502c140-b1c3-4e0b-b3b3-e60ce85b0eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1232f2eb-6c2c-466f-905e-67b624031508",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e13ef8f-cb64-4a9d-b6df-7024534b03c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
    "    # Initialize these variables which will be set in this if statement. Each of these\n",
    "    #   variables is model specific.\n",
    "    model_ft = None\n",
    "    input_size = 0\n",
    "\n",
    "    if model_name == \"resnet\":\n",
    "        \"\"\" Resnet18, resnet34, resnet50, resnet101\n",
    "        \"\"\"\n",
    "        model_ft = models.resnet50(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "\n",
    "    elif model_name == \"vgg\":\n",
    "        \"\"\" VGG11_bn\n",
    "        \"\"\"\n",
    "        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "\n",
    "    elif model_name == \"densenet\":\n",
    "        \"\"\" Densenet121\n",
    "        \"\"\"\n",
    "        model_ft = models.densenet121(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier.in_features\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"inception\":\n",
    "        \"\"\" Inception v3\n",
    "        Be careful, expects (299,299) sized images and has auxiliary output\n",
    "        \"\"\"\n",
    "        model_ft = models.inception_v3(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        # Handle the auxilary net\n",
    "        num_ftrs = model_ft.AuxLogits.fc.in_features\n",
    "        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        # Handle the primary net\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 299\n",
    "\n",
    "    else:\n",
    "        print(\"Invalid model name, exiting...\")\n",
    "        exit()\n",
    "    return model_ft, input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f18dce0a-57c7-4d20-9dd1-245154d1f800",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'densenet'\n",
    "num_classes = 7\n",
    "feature_extract = False\n",
    "# Initialize the model for this run\n",
    "model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n",
    "# Define the device:\n",
    "device = torch.device('cuda:0')\n",
    "# Put the model on the device:\n",
    "model = model_ft.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30acfbb-8555-40f8-9071-4db137509d31",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cfb603db-f566-4fab-b32f-91a8bf442c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_mean = (0.49139968, 0.48215827, 0.44653124)\n",
    "norm_std = (0.24703233, 0.24348505, 0.26158768)\n",
    "# define the transformation of the train images.\n",
    "train_transform = transforms.Compose([transforms.Resize((input_size,input_size)),transforms.RandomHorizontalFlip(),\n",
    "                                      transforms.RandomVerticalFlip(),transforms.RandomRotation(20),\n",
    "                                      transforms.ColorJitter(brightness=0.1, contrast=0.1, hue=0.1),\n",
    "                                        transforms.ToTensor(), transforms.Normalize(norm_mean, norm_std)])\n",
    "# define the transformation of the val images.\n",
    "val_transform = transforms.Compose([transforms.Resize((input_size,input_size)), transforms.ToTensor(),\n",
    "                                    transforms.Normalize(norm_mean, norm_std)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a569064-bee1-468d-8f9f-3cc19011924d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HAM10000(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Load data and get label\n",
    "        X = Image.open(self.df['path'][index])\n",
    "        y = torch.tensor(int(self.df['cell_type_idx'][index]))\n",
    "\n",
    "        if self.transform:\n",
    "            X = self.transform(X)\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f61472ad-dcef-4859-a5c2-92347c8cb0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = HAM10000(df_train, transform=train_transform)\n",
    "train_loader = DataLoader(training_set, batch_size=32, shuffle=True, num_workers=4)\n",
    "# Same for the validation set:\n",
    "validation_set = HAM10000(df_val, transform=train_transform)\n",
    "val_loader = DataLoader(validation_set, batch_size=32, shuffle=False, num_workers=4)\n",
    "loaders = {'train':train_loader, 'val':val_loader}\n",
    "dataset_sizes = {'train':len(training_set), 'val':len(validation_set)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ba13a4b2-80b9-4f25-9ad1-4712b29c2308",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1ec855-e8c3-471f-bbf2-6feefc25c8d2",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc59efd3-da6b-4cef-a58d-b15bf9065aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ad71f82-a9ec-4a1f-bb59-e5d95bf2bcea",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loss_train, total_acc_train = [],[]\n",
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    model.train()\n",
    "    train_loss = AverageMeter()\n",
    "    train_acc = AverageMeter()\n",
    "    curr_iter = (epoch - 1) * len(train_loader)\n",
    "    for i, data in enumerate(train_loader):\n",
    "        images, labels = data\n",
    "        N = images.size(0)\n",
    "        # print('image shape:',images.size(0), 'label shape',labels.size(0))\n",
    "        images = Variable(images).to(device)\n",
    "        labels = Variable(labels).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        prediction = outputs.max(1, keepdim=True)[1]\n",
    "        train_acc.update(prediction.eq(labels.view_as(prediction)).sum().item()/N)\n",
    "        train_loss.update(loss.item())\n",
    "        curr_iter += 1\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print('[epoch %d], [iter %d / %d], [train loss %.5f], [train acc %.5f]' % (\n",
    "                epoch, i + 1, len(train_loader), train_loss.avg, train_acc.avg))\n",
    "            total_loss_train.append(train_loss.avg)\n",
    "            total_acc_train.append(train_acc.avg)\n",
    "    return train_loss.avg, train_acc.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b0fdd77a-9488-43d1-9405-66ba6f6b3362",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion, optimizer, epoch):\n",
    "    model.eval()\n",
    "    val_loss = AverageMeter()\n",
    "    val_acc = AverageMeter()\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(val_loader):\n",
    "            images, labels = data\n",
    "            N = images.size(0)\n",
    "            images = Variable(images).to(device)\n",
    "            labels = Variable(labels).to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            prediction = outputs.max(1, keepdim=True)[1]\n",
    "\n",
    "            val_acc.update(prediction.eq(labels.view_as(prediction)).sum().item()/N)\n",
    "\n",
    "            val_loss.update(criterion(outputs, labels).item())\n",
    "\n",
    "    print('------------------------------------------------------------')\n",
    "    print('[epoch %d], [val loss %.5f], [val acc %.5f]' % (epoch, val_loss.avg, val_acc.avg))\n",
    "    print('------------------------------------------------------------')\n",
    "    return val_loss.avg, val_acc.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd573d5-c232-4b47-827e-4d7284887a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1], [iter 100 / 1124], [train loss 1.27781], [train acc 0.52187]\n",
      "[epoch 1], [iter 200 / 1124], [train loss 1.13866], [train acc 0.57828]\n",
      "[epoch 1], [iter 300 / 1124], [train loss 1.07006], [train acc 0.60625]\n",
      "[epoch 1], [iter 400 / 1124], [train loss 1.01230], [train acc 0.62398]\n",
      "[epoch 1], [iter 500 / 1124], [train loss 0.98033], [train acc 0.63656]\n",
      "[epoch 1], [iter 600 / 1124], [train loss 0.94272], [train acc 0.65010]\n",
      "[epoch 1], [iter 700 / 1124], [train loss 0.91199], [train acc 0.66013]\n",
      "[epoch 1], [iter 800 / 1124], [train loss 0.88379], [train acc 0.66977]\n",
      "[epoch 1], [iter 900 / 1124], [train loss 0.86007], [train acc 0.67833]\n",
      "[epoch 1], [iter 1000 / 1124], [train loss 0.83920], [train acc 0.68550]\n",
      "[epoch 1], [iter 1100 / 1124], [train loss 0.82092], [train acc 0.69247]\n",
      "------------------------------------------------------------\n",
      "[epoch 1], [val loss 0.45658], [val acc 0.84339]\n",
      "------------------------------------------------------------\n",
      "*****************************************************\n",
      "best record: [epoch 1], [val loss 0.45658], [val acc 0.84339]\n",
      "*****************************************************\n",
      "[epoch 2], [iter 100 / 1124], [train loss 0.61974], [train acc 0.76812]\n",
      "[epoch 2], [iter 200 / 1124], [train loss 0.60868], [train acc 0.76984]\n",
      "[epoch 2], [iter 300 / 1124], [train loss 0.61734], [train acc 0.76792]\n",
      "[epoch 2], [iter 400 / 1124], [train loss 0.60505], [train acc 0.77195]\n",
      "[epoch 2], [iter 500 / 1124], [train loss 0.60184], [train acc 0.77287]\n",
      "[epoch 2], [iter 600 / 1124], [train loss 0.59506], [train acc 0.77453]\n",
      "[epoch 2], [iter 700 / 1124], [train loss 0.58616], [train acc 0.77844]\n",
      "[epoch 2], [iter 800 / 1124], [train loss 0.57969], [train acc 0.78063]\n",
      "[epoch 2], [iter 900 / 1124], [train loss 0.57398], [train acc 0.78292]\n",
      "[epoch 2], [iter 1000 / 1124], [train loss 0.56878], [train acc 0.78425]\n",
      "[epoch 2], [iter 1100 / 1124], [train loss 0.56310], [train acc 0.78631]\n",
      "------------------------------------------------------------\n",
      "[epoch 2], [val loss 0.46763], [val acc 0.83905]\n",
      "------------------------------------------------------------\n",
      "[epoch 3], [iter 100 / 1124], [train loss 0.46890], [train acc 0.82156]\n",
      "[epoch 3], [iter 200 / 1124], [train loss 0.47426], [train acc 0.82109]\n",
      "[epoch 3], [iter 300 / 1124], [train loss 0.46783], [train acc 0.82229]\n",
      "[epoch 3], [iter 400 / 1124], [train loss 0.46366], [train acc 0.82367]\n",
      "[epoch 3], [iter 500 / 1124], [train loss 0.46503], [train acc 0.82337]\n",
      "[epoch 3], [iter 600 / 1124], [train loss 0.46634], [train acc 0.82281]\n",
      "[epoch 3], [iter 700 / 1124], [train loss 0.46178], [train acc 0.82496]\n",
      "[epoch 3], [iter 800 / 1124], [train loss 0.45827], [train acc 0.82645]\n",
      "[epoch 3], [iter 900 / 1124], [train loss 0.45799], [train acc 0.82708]\n",
      "[epoch 3], [iter 1000 / 1124], [train loss 0.45634], [train acc 0.82675]\n",
      "[epoch 3], [iter 1100 / 1124], [train loss 0.45412], [train acc 0.82747]\n",
      "------------------------------------------------------------\n",
      "[epoch 3], [val loss 0.48606], [val acc 0.82988]\n",
      "------------------------------------------------------------\n",
      "[epoch 4], [iter 100 / 1124], [train loss 0.38653], [train acc 0.84937]\n",
      "[epoch 4], [iter 200 / 1124], [train loss 0.40712], [train acc 0.84234]\n",
      "[epoch 4], [iter 300 / 1124], [train loss 0.40390], [train acc 0.84250]\n",
      "[epoch 4], [iter 400 / 1124], [train loss 0.39476], [train acc 0.84648]\n",
      "[epoch 4], [iter 500 / 1124], [train loss 0.39578], [train acc 0.84537]\n",
      "[epoch 4], [iter 600 / 1124], [train loss 0.39519], [train acc 0.84479]\n",
      "[epoch 4], [iter 700 / 1124], [train loss 0.39944], [train acc 0.84397]\n",
      "[epoch 4], [iter 800 / 1124], [train loss 0.39889], [train acc 0.84539]\n",
      "[epoch 4], [iter 900 / 1124], [train loss 0.39681], [train acc 0.84660]\n",
      "[epoch 4], [iter 1000 / 1124], [train loss 0.39323], [train acc 0.84828]\n",
      "[epoch 4], [iter 1100 / 1124], [train loss 0.39042], [train acc 0.84994]\n",
      "------------------------------------------------------------\n",
      "[epoch 4], [val loss 0.41178], [val acc 0.84530]\n",
      "------------------------------------------------------------\n",
      "*****************************************************\n",
      "best record: [epoch 4], [val loss 0.41178], [val acc 0.84530]\n",
      "*****************************************************\n",
      "[epoch 5], [iter 100 / 1124], [train loss 0.34814], [train acc 0.86531]\n",
      "[epoch 5], [iter 200 / 1124], [train loss 0.34205], [train acc 0.86625]\n",
      "[epoch 5], [iter 300 / 1124], [train loss 0.33813], [train acc 0.86958]\n",
      "[epoch 5], [iter 400 / 1124], [train loss 0.34112], [train acc 0.86883]\n",
      "[epoch 5], [iter 500 / 1124], [train loss 0.33985], [train acc 0.87044]\n",
      "[epoch 5], [iter 600 / 1124], [train loss 0.34506], [train acc 0.86813]\n",
      "[epoch 5], [iter 700 / 1124], [train loss 0.34201], [train acc 0.86955]\n",
      "[epoch 5], [iter 800 / 1124], [train loss 0.34001], [train acc 0.87055]\n",
      "[epoch 5], [iter 900 / 1124], [train loss 0.33632], [train acc 0.87194]\n",
      "[epoch 5], [iter 1000 / 1124], [train loss 0.33567], [train acc 0.87278]\n",
      "[epoch 5], [iter 1100 / 1124], [train loss 0.33456], [train acc 0.87270]\n",
      "------------------------------------------------------------\n",
      "[epoch 5], [val loss 0.40821], [val acc 0.86048]\n",
      "------------------------------------------------------------\n",
      "*****************************************************\n",
      "best record: [epoch 5], [val loss 0.40821], [val acc 0.86048]\n",
      "*****************************************************\n",
      "[epoch 6], [iter 100 / 1124], [train loss 0.25865], [train acc 0.89625]\n",
      "[epoch 6], [iter 200 / 1124], [train loss 0.28873], [train acc 0.88672]\n",
      "[epoch 6], [iter 300 / 1124], [train loss 0.29039], [train acc 0.88885]\n",
      "[epoch 6], [iter 400 / 1124], [train loss 0.28829], [train acc 0.89086]\n",
      "[epoch 6], [iter 500 / 1124], [train loss 0.28630], [train acc 0.89100]\n",
      "[epoch 6], [iter 600 / 1124], [train loss 0.29175], [train acc 0.88813]\n",
      "[epoch 6], [iter 700 / 1124], [train loss 0.29351], [train acc 0.88763]\n",
      "[epoch 6], [iter 800 / 1124], [train loss 0.29486], [train acc 0.88762]\n",
      "[epoch 6], [iter 900 / 1124], [train loss 0.29719], [train acc 0.88656]\n",
      "[epoch 6], [iter 1000 / 1124], [train loss 0.29544], [train acc 0.88700]\n",
      "[epoch 6], [iter 1100 / 1124], [train loss 0.29426], [train acc 0.88741]\n",
      "------------------------------------------------------------\n",
      "[epoch 6], [val loss 0.40215], [val acc 0.88000]\n",
      "------------------------------------------------------------\n",
      "*****************************************************\n",
      "best record: [epoch 6], [val loss 0.40215], [val acc 0.88000]\n",
      "*****************************************************\n",
      "[epoch 7], [iter 100 / 1124], [train loss 0.26545], [train acc 0.89625]\n",
      "[epoch 7], [iter 200 / 1124], [train loss 0.26580], [train acc 0.89563]\n",
      "[epoch 7], [iter 300 / 1124], [train loss 0.26174], [train acc 0.89729]\n",
      "[epoch 7], [iter 400 / 1124], [train loss 0.26581], [train acc 0.89656]\n",
      "[epoch 7], [iter 500 / 1124], [train loss 0.26100], [train acc 0.89906]\n",
      "[epoch 7], [iter 600 / 1124], [train loss 0.26854], [train acc 0.89672]\n",
      "[epoch 7], [iter 700 / 1124], [train loss 0.26910], [train acc 0.89804]\n",
      "[epoch 7], [iter 800 / 1124], [train loss 0.26612], [train acc 0.89957]\n",
      "[epoch 7], [iter 900 / 1124], [train loss 0.26195], [train acc 0.90087]\n",
      "[epoch 7], [iter 1000 / 1124], [train loss 0.26171], [train acc 0.90044]\n",
      "[epoch 7], [iter 1100 / 1124], [train loss 0.26128], [train acc 0.90060]\n",
      "------------------------------------------------------------\n",
      "[epoch 7], [val loss 0.53155], [val acc 0.79708]\n",
      "------------------------------------------------------------\n",
      "[epoch 8], [iter 100 / 1124], [train loss 0.23906], [train acc 0.90438]\n",
      "[epoch 8], [iter 200 / 1124], [train loss 0.23595], [train acc 0.90812]\n",
      "[epoch 8], [iter 300 / 1124], [train loss 0.24160], [train acc 0.90698]\n",
      "[epoch 8], [iter 400 / 1124], [train loss 0.24167], [train acc 0.90750]\n",
      "[epoch 8], [iter 500 / 1124], [train loss 0.24027], [train acc 0.90763]\n",
      "[epoch 8], [iter 600 / 1124], [train loss 0.23969], [train acc 0.90906]\n",
      "[epoch 8], [iter 700 / 1124], [train loss 0.23922], [train acc 0.90915]\n",
      "[epoch 8], [iter 800 / 1124], [train loss 0.24106], [train acc 0.90797]\n",
      "[epoch 8], [iter 900 / 1124], [train loss 0.23944], [train acc 0.90931]\n",
      "[epoch 8], [iter 1000 / 1124], [train loss 0.23846], [train acc 0.90975]\n",
      "[epoch 8], [iter 1100 / 1124], [train loss 0.23754], [train acc 0.90957]\n",
      "------------------------------------------------------------\n",
      "[epoch 8], [val loss 0.41563], [val acc 0.85512]\n",
      "------------------------------------------------------------\n",
      "[epoch 9], [iter 100 / 1124], [train loss 0.20455], [train acc 0.92531]\n",
      "[epoch 9], [iter 200 / 1124], [train loss 0.21621], [train acc 0.91875]\n",
      "[epoch 9], [iter 300 / 1124], [train loss 0.21348], [train acc 0.92052]\n",
      "[epoch 9], [iter 400 / 1124], [train loss 0.20812], [train acc 0.92250]\n",
      "[epoch 9], [iter 500 / 1124], [train loss 0.20844], [train acc 0.92212]\n",
      "[epoch 9], [iter 600 / 1124], [train loss 0.20600], [train acc 0.92271]\n",
      "[epoch 9], [iter 700 / 1124], [train loss 0.20759], [train acc 0.92201]\n",
      "[epoch 9], [iter 800 / 1124], [train loss 0.20618], [train acc 0.92207]\n",
      "[epoch 9], [iter 900 / 1124], [train loss 0.20371], [train acc 0.92267]\n",
      "[epoch 9], [iter 1000 / 1124], [train loss 0.20552], [train acc 0.92150]\n",
      "[epoch 9], [iter 1100 / 1124], [train loss 0.20462], [train acc 0.92159]\n",
      "------------------------------------------------------------\n",
      "[epoch 9], [val loss 0.37640], [val acc 0.87923]\n",
      "------------------------------------------------------------\n",
      "[epoch 10], [iter 100 / 1124], [train loss 0.24740], [train acc 0.91187]\n",
      "[epoch 10], [iter 200 / 1124], [train loss 0.22920], [train acc 0.91469]\n",
      "[epoch 10], [iter 300 / 1124], [train loss 0.20833], [train acc 0.92177]\n",
      "[epoch 10], [iter 400 / 1124], [train loss 0.20361], [train acc 0.92375]\n",
      "[epoch 10], [iter 500 / 1124], [train loss 0.20270], [train acc 0.92400]\n",
      "[epoch 10], [iter 600 / 1124], [train loss 0.19930], [train acc 0.92510]\n",
      "[epoch 10], [iter 700 / 1124], [train loss 0.19704], [train acc 0.92621]\n"
     ]
    }
   ],
   "source": [
    "epoch_num = 10\n",
    "best_val_acc = 0\n",
    "total_loss_val, total_acc_val = [],[]\n",
    "for epoch in range(1, epoch_num+1):\n",
    "    loss_train, acc_train = train(train_loader, model, criterion, optimizer, epoch)\n",
    "    loss_val, acc_val = validate(val_loader, model, criterion, optimizer, epoch)\n",
    "    total_loss_val.append(loss_val)\n",
    "    total_acc_val.append(acc_val)\n",
    "    if acc_val > best_val_acc:\n",
    "        best_val_acc = acc_val\n",
    "        print('*****************************************************')\n",
    "        print('best record: [epoch %d], [val loss %.5f], [val acc %.5f]' % (epoch, loss_val, acc_val))\n",
    "        print('*****************************************************')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce182f3-350b-402d-a0d4-04af08f36efa",
   "metadata": {},
   "source": [
    "## Attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2cb2e7a5-b297-4757-8842-ec8ff413fcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install captum\n",
    "!pip install cleverhans\n",
    "from captum.attr import IntegratedGradients\n",
    "from captum.attr import Saliency\n",
    "from captum.attr import DeepLift\n",
    "from captum.attr import NoiseTunnel\n",
    "from captum.attr import GradientShap\n",
    "from captum.attr import GuidedGradCam\n",
    "from captum.attr import LimeBase\n",
    "from captum.attr import KernelShap\n",
    "from captum.attr import Occlusion\n",
    "from captum.attr import visualization as viz\n",
    "from cleverhans.torch.attacks.fast_gradient_method import fast_gradient_method\n",
    "from cleverhans.torch.attacks.carlini_wagner_l2 import carlini_wagner_l2\n",
    "from cleverhans.torch.attacks.projected_gradient_descent import (\n",
    "    projected_gradient_descent\n",
    ")\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336c6cb9-4948-4d1b-b38b-b0cd478b5d11",
   "metadata": {},
   "source": [
    "## Statistical Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6bab0763-3e50-441a-a8bc-b123c4d5fb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mean_abs_dev(attr): \n",
    "    scores = []\n",
    "    for i in range(len(attr)):\n",
    "        a = attr[i].flatten()\n",
    "        avg = np.mean(a)\n",
    "        deviation = a - avg \n",
    "        absolute_deviation = np.abs(deviation)\n",
    "        result = np.mean(absolute_deviation)\n",
    "        scores.append(result)\n",
    "    return scores    \n",
    "def compute_median_abs_dev(attr): \n",
    "    scores = []\n",
    "    for i in range(len(attr)):\n",
    "        a = attr[i].flatten()\n",
    "        med = np.median(a)\n",
    "        deviation = a - med \n",
    "        abs_deviation = np.abs(deviation)\n",
    "        result = np.median(abs_deviation)\n",
    "        scores.append(result)\n",
    "    return scores \n",
    "def compute_iqr(attr):\n",
    "    #inter-quartile range\n",
    "    scores = []\n",
    "    for i in range(len(attr)):\n",
    "        a = attr[i].flatten()\n",
    "        score_75 = np.percentile(a, 75)\n",
    "        score_25 = np.percentile(a, 25)\n",
    "        score_qt = score_75 - score_25\n",
    "        scores.append(score_qt)\n",
    "    return scores\n",
    "    \n",
    "def compute_coef_var(attr):\n",
    "    scores = []\n",
    "    for i in range(len(attr)):\n",
    "        a = attr[i].flatten()\n",
    "        m = np.mean(a)\n",
    "        st = np.std(attr[i])\n",
    "        sc = m/st\n",
    "        scores.append(sc)\n",
    "    return scores\n",
    "\n",
    "def compute_coef_iqr(attr):\n",
    "    scores = []\n",
    "    for i in range(len(attr)):\n",
    "        a = attr[i].flatten()\n",
    "        score_75 = np.percentile(a, 75)\n",
    "        score_25 = np.percentile(a, 25)\n",
    "        score_qt = (score_75 - score_25)/(score_75 + score_25)\n",
    "        scores.append(score_qt)\n",
    "    return scores\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4ac7e4-15f5-4ad5-bc63-50f36ce8560b",
   "metadata": {},
   "outputs": [],
   "source": [
    "interested_layers = [14,24,35,45,56,67,70]\n",
    "\n",
    "def collect_layers(model, interested_layers):\n",
    "\tif model.framework == 'keras':\n",
    "\t\toutputs = [layer.output for layer in model.layers]\n",
    "\telif model.framework == 'tensorflow':\n",
    "\t\toutputs = model.layers\n",
    "\n",
    "\toutputs = [output for i, output in enumerate(outputs) if i in interested_layers]\n",
    "\tprint(outputs)\n",
    "\tfeatures = []\n",
    "\tfor output in outputs:\n",
    "\t\tprint(output)\n",
    "\t\tif len(output.get_shape())== 4:\n",
    "\t\t\tfeatures.append(\n",
    "\t\t\t\ttf.reduce_mean(output, axis = (1, 2))\n",
    "\t\t\t)\n",
    "\t\telse:\n",
    "\t\t\tfeatures.append(output)\n",
    "\treturn features\n",
    "\n",
    "\t\t\t\n",
    "def evaluate_features(x, model, features):\n",
    "\tx = np.array(x)\n",
    "\tif len(x.shape) == 3:\n",
    "\t\t_x = np.expand_dims(x, 0) \n",
    "\telse:\n",
    "\t\t_x = x\n",
    "\n",
    "\tbatch_size = 500\n",
    "\tnum_iters = int(math.ceil(len(_x) * 1.0 / batch_size))\n",
    "\n",
    "\touts = []\n",
    "\tfor i in range(num_iters):\n",
    "\t\tx_batch = _x[i * batch_size: (i+1) * batch_size]\n",
    "\t\tout = model.sess.run(features, \n",
    "\t\t\tfeed_dict = {model.input_ph: x_batch})\n",
    "\n",
    "\t\touts.append(out)\n",
    "\n",
    "\tnum_layers = len(outs[0])\n",
    "\toutputs = []\n",
    "\tfor l in range(num_layers):\n",
    "\t\toutputs.append(np.concatenate([outs[s][l] for s in range(len(outs))]))\n",
    "\n",
    "\t# (3073, 64)\n",
    "\t# (3073, 64)\n",
    "\t# (3073, 128)\n",
    "\t# (3073, 128)\n",
    "\t# (3073, 256)\n",
    "\t# (3073, 256)\n",
    "\t# (3073, 10)\n",
    "\t# (3073, 1)\n",
    "\toutputs = np.concatenate(outputs, axis = 1)\n",
    "\tprob = outputs[:,-model.num_classes:]\n",
    "\tlabel = np.argmax(prob[-1])\n",
    "\tprint('outputs', outputs.shape)\n",
    "\tprint('prob[:, label]', np.expand_dims(prob[:, label], axis = 1).shape)\n",
    "\toutputs = np.concatenate([outputs, np.expand_dims(prob[:, label], axis = 1)], axis = 1)\n",
    "\n",
    "\treturn outputs\n",
    "\n",
    "\n",
    "def loo_ml_instance(sample, reference, model, features):\n",
    "\th,w,c = sample.shape\n",
    "\tsample = sample.reshape(-1)\n",
    "\treference = reference.reshape(-1)\n",
    "\n",
    "\tdata = []\n",
    "\tst = time.time()\n",
    "\tpositions = np.ones((h*w*c + 1, h*w*c), dtype = np.bool)\n",
    "\tfor i in range(h*w*c):\n",
    "\t\tpositions[i, i] = False\n",
    "\t\n",
    "\tdata = np.where(positions, sample, reference)\n",
    "\n",
    "\tdata = data.reshape((-1, h, w, c))\n",
    "\tfeatures_val = evaluate_features(data, model, features) # (3072+1, 906+1)\n",
    "\tst1 = time.time()\n",
    "\n",
    "\treturn features_val\n",
    "\n",
    "\n",
    "def generate_ml_loo_features(args, data_model, reference, model, x, interested_layers):\n",
    "\t# print(args.attack)\n",
    "\t# x = load_examples(data_model, attack)\n",
    "\tfeatures = collect_layers(model, interested_layers)\n",
    "\n",
    "\tcat = {'original':'ori', 'adv':'adv', 'noisy':'noisy'}\n",
    "\tdt = {'train':'train', 'test':'test'}\n",
    "\tstat_names = ['std', 'variance', 'con', 'kurtosis', 'skewness', 'quantile', 'mad']\n",
    "\n",
    "\tcombined_features = {data_type: {} for data_type in ['test', 'train']}\n",
    "\tfor data_type in ['test', 'train']:\n",
    "\t\tprint('data_type', data_type)\n",
    "\t\tfor category in ['original', 'adv']:\n",
    "\t\t\tprint('category', category)\n",
    "\t\t\tall_features = []\n",
    "\t\t\tfor i, sample in enumerate(x[data_type][category]):\n",
    "\t\t\t\tprint('Generating ML-LOO for {}th sample...'.format(i))\n",
    "\t\t\t\tfeatures_val = loo_ml_instance(sample, reference, model, features)\n",
    "\t\t\t\t\n",
    "\t\t\t\t# (3073, 907)\n",
    "\t\t\t\tprint('features_val.shape', features_val.shape)\n",
    "\t\t\t\tfeatures_val = np.transpose(features_val)[:,:-1]\n",
    "\t\t\t\tprint('features_val.shape', features_val.shape)\n",
    "\t\t\t\t# (906, 3073)\n",
    "\t\t\t\tsingle_feature = []\n",
    "\t\t\t\tfor stat_name in stat_names:\n",
    "\t\t\t\t\tprint('stat_name', stat_name)\n",
    "\t\t\t\t\tsingle_feature.append(calculate(features_val, stat_name))\n",
    "\n",
    "\t\t\t\tsingle_feature = np.array(single_feature)\n",
    "\t\t\t\tprint('single_feature', single_feature.shape)\n",
    "\t\t\t\t# (k, 906)\n",
    "\t\t\t\tall_features.append(single_feature)\n",
    "\t\t\tprint('all_features', np.array(all_features).shape)\n",
    "\t\t\tcombined_features[data_type][category] = np.array(all_features)\n",
    "\n",
    "\t\t\tnp.save('{}/data/{}_{}_{}_{}_{}.npy'.format(\n",
    "\t\t\t\tdata_model,\n",
    "\t\t\t\targs.data_sample,\n",
    "\t\t\t\tdt[data_type],\n",
    "\t\t\t\tcat[category],\n",
    "\t\t\t\targs.attack, \n",
    "\t\t\t\targs.det), \n",
    "\t\t\t\tcombined_features[data_type][category])\n",
    "\n",
    "\treturn combined_features\n",
    "\n",
    "\n",
    "def compute_stat_single_layer(output):\n",
    "\t# l2dist = pdist(output)\n",
    "\t# l1dist = pdist(output, 'minkowski', p = 1)\n",
    "\t# sl2dist = pdist(X, 'seuclidean')\n",
    "\tvariance = np.sum(np.var(output, axis = 0))\n",
    "\t# on = np.sum(np.linalg.norm(output, ord = 1, axis = 0))\n",
    "\tcon = np.sum(np.linalg.norm(output - np.mean(output, axis = 0), ord = 1, axis = 0))\n",
    "\n",
    "\treturn variance, con\n",
    "\n",
    "\n",
    "def load_features(data_model, attacks):\n",
    "\tdef softmax(x, axis):\n",
    "\t\t\"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "\t\te_x = np.exp(x - np.max(x, axis = axis, keepdims = True))\n",
    "\t\treturn e_x / e_x.sum(axis=axis, keepdims = True) # only difference      \n",
    "\n",
    "\tcat = {'original':'', 'adv':'_adv', 'noisy':'_noisy'}\n",
    "\tdt = {'train':'_train', 'test':''}\n",
    "\tfeatures = {attack: {'train': {}, 'test': {}} for attack in attacks}\n",
    "\n",
    "\tnormalizer = {}\n",
    "\tfor attack in attacks:\n",
    "\t\tfor data_type in ['train', 'test']:\n",
    "\t\t\tfor category in ['original', 'adv']:\n",
    "\t\t\t\tprint('Loading data...')\n",
    "\t\t\t\tfeature = np.load('{}/data/{}{}{}_{}_{}.npy'.format(data_model,'x_val200',  \n",
    "\t\t\t\t\tdt[data_type], \n",
    "\t\t\t\t\tcat[category], \n",
    "\t\t\t\t\tattack, \n",
    "\t\t\t\t\t'ml_loo')) # [n, 3073, ...]\n",
    "\t\t\t\tn = len(feature)\n",
    "\t\t\t\tprint('Processing...')\n",
    "\t\t\t\tnums = [0,64,64,128,128,256,256,10]\n",
    "\t\t\t\tsplits = np.cumsum(nums) # [0,64,128,...]\n",
    "\t\t\t\tprocessed = []\n",
    "\t\t\t\tfor j, s in enumerate(splits):\n",
    "\t\t\t\t\tif j < len(splits) - 1:\n",
    "\t\t\t\t\t\tseparated = feature[:, :-1, s:splits[j+1]]\n",
    "\n",
    "\t\t\t\t\t\tif j == len(splits) - 2:\n",
    "\t\t\t\t\t\t\tseparated = softmax(separated, axis = -1)\n",
    "\t\t\t\t\t\t\t\n",
    "\t\t\t\t\t\tdist = np.var(separated, axis = 1) # [n, ...]\n",
    "\t\t\t\t\t\tif data_type == 'train' and category == 'original' and attack == 'linfpgd':\n",
    "\t\t\t\t\t\t\tavg_dist = np.mean(dist, axis = 0)\n",
    "\t\t\t\t\t\t\tnormalizer[j] = avg_dist\n",
    "\n",
    "\t\t\t\t\t\t# dist /= normalizer[j]\n",
    "\t\t\t\t\t\tdist = np.sqrt(dist)\n",
    "\n",
    "\t\t\t\t\t\t# max_dist = np.max(dist, axis = -1)\n",
    "\t\t\t\t\t\tprint(np.mean(dist))\n",
    "\t\t\t\t\t\tprocessed.append(dist.T)\n",
    "\n",
    "\t\t\t\tprocessed = np.concatenate(processed, axis = 0).T\n",
    "\t\t\t\t# processed = np.concatenate(processed, axis = )\n",
    "\n",
    "\n",
    "\t\t\t\tprint(processed.shape)\n",
    "\n",
    "\t\t\t\tfeatures[attack][data_type][category] = processed\n",
    "\n",
    "\treturn features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67af23b6-dc66-4e6d-92f2-e6a66f87dca8",
   "metadata": {},
   "source": [
    "## Integrated Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "082e9eca-8961-488a-b386-c631210609d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "dataiter = iter(val_loader)\n",
    "\n",
    "igmedianAbs_ben = []\n",
    "igmeanAbs_ben = []\n",
    "igiqr_ben = []\n",
    "igcoef_var_ben=[]\n",
    "igcoef_iqr_ben = []\n",
    "\n",
    "igmedianAbs_bena = []\n",
    "igmeanAbs_bena = []\n",
    "igiqr_bena = []\n",
    "igcoef_var_bena=[]\n",
    "igcoef_iqr_bena = []\n",
    "\n",
    "for i in range(30):\n",
    "    images, labels = next(dataiter)\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "    for ind in range(32):\n",
    "        input1 = images[ind].unsqueeze(0)\n",
    "        x_logits = model(images)\n",
    "        ig = IntegratedGradients(model)\n",
    "        a_batch_benign = ig.attribute(input1, target=labels[ind]).sum(axis=1).cpu().detach().numpy()\n",
    "        # attr_ig = ig.attribute(input1, target=labels[ind])\n",
    "        # attr_ig = np.transpose(attr_ig.squeeze().cpu().detach().numpy(), (1, 2, 0))\n",
    "        igmeanAbs_ben += compute_mean_abs_dev(a_batch_benign)\n",
    "        igmedianAbs_ben += compute_median_abs_dev(a_batch_benign)\n",
    "        igiqr_ben += compute_iqr(a_batch_benign)\n",
    "        igcoef_var_ben += compute_coef_var(a_batch_benign)\n",
    "        igcoef_iqr_ben += compute_coef_iqr(a_batch_benign)\n",
    "        # torch.cuda.empty_cache()\n",
    "        images_pgd = fast_gradient_method(model, input1, 0.3, np.inf)\n",
    "        _, y_pred_pgd = model(input1).max(1)\n",
    "        # index = (y_pred_pgd != labels)\n",
    "        # pgd_images = images_pgd[index]\n",
    "        # y_pred_pgd = y_pred_pgd[index]\n",
    "        a_batch_attack = ig.attribute(inputs=images_pgd, target=y_pred_pgd).sum(axis=1).cpu().detach().numpy()\n",
    "        igmeanAbs_bena += compute_mean_abs_dev(a_batch_attack)\n",
    "        igmedianAbs_bena += compute_median_abs_dev(a_batch_attack)\n",
    "        igiqr_bena += compute_iqr(a_batch_attack)\n",
    "        igcoef_var_bena += compute_coef_var(a_batch_attack)\n",
    "        igcoef_iqr_bena += compute_coef_iqr(a_batch_attack)\n",
    "        # images_pgd = np.transpose((images[ind].cpu().detach().numpy() / 2) + 0.5, (1, 2, 0))\n",
    "        # attr_ig = ig.attribute(inputs=images_pgd, target=y_pred_pgd)\n",
    "        # attr_ig = np.transpose(attr_ig.squeeze().cpu().detach().numpy(), (1, 2, 0))\n",
    "        # _ = viz.visualize_image_attr(attr_ig, original_image, method=\"blended_heat_map\",sign=\"all\",\n",
    "        #                   show_colorbar=True, title=\"Overlayed Integrated Gradients\")\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a42f8f19-eeb1-45af-8cb2-d294433142ec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(igiqr_ben, label='clean', color='blue')\n",
    "plt.hist(igiqr_bena, label='adv', alpha=0.7, color='red')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5361cb43-8c6a-49d1-acfc-76146eeabac8",
   "metadata": {},
   "source": [
    "## Saliency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be1111b-d406-42f7-92c0-886a732cad19",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "ind = 2\n",
    "dataiter = iter(val_loader)\n",
    "images, labels = next(dataiter)\n",
    "images = images.to(device)\n",
    "labels = labels.to(device)\n",
    "\n",
    "\n",
    "salmedianAbs_ben = []\n",
    "salmeanAbs_ben = []\n",
    "saliqr_ben = []\n",
    "salcoef_var_ben=[]\n",
    "salcoef_iqr_ben = []\n",
    "\n",
    "salmedianAbs_bena = []\n",
    "salmeanAbs_bena = []\n",
    "saliqr_bena = []\n",
    "salcoef_var_bena=[]\n",
    "salcoef_iqr_bena = []\n",
    "\n",
    "for i in range(30):\n",
    "    dataiter = iter(val_loader)\n",
    "    images, labels = next(dataiter)\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "    for ind in range(32):\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        input1 = images[ind].unsqueeze(0)\n",
    "        x_logits = model(images)\n",
    "        ig = Saliency(model)\n",
    "        a_batch_benign = ig.attribute(input1, target=labels[ind]).sum(axis=1).cpu().detach().numpy()\n",
    "        salmeanAbs_ben += compute_mean_abs_dev(a_batch_benign)\n",
    "        salmedianAbs_ben += compute_median_abs_dev(a_batch_benign)\n",
    "        saliqr_ben += compute_iqr(a_batch_benign)\n",
    "        salcoef_var_ben += compute_coef_var(a_batch_benign)\n",
    "        salcoef_iqr_ben += compute_coef_iqr(a_batch_benign)\n",
    "        # torch.cuda.empty_cache()\n",
    "        images_pgd = fast_gradient_method(model, input1, 0.1, np.inf)\n",
    "        _, y_pred_pgd = model(input1).max(1)\n",
    "        # index = (y_pred_pgd != labels)\n",
    "        # pgd_images = images_pgd[index]\n",
    "        # y_pred_pgd = y_pred_pgd[index]\n",
    "        a_batch_attack = ig.attribute(inputs=images_pgd, target=y_pred_pgd).sum(axis=1).cpu().detach().numpy()\n",
    "        salmeanAbs_bena += compute_mean_abs_dev(a_batch_attack)\n",
    "        salmedianAbs_bena += compute_median_abs_dev(a_batch_attack)\n",
    "        saliqr_bena += compute_iqr(a_batch_attack)\n",
    "        salcoef_var_bena += compute_coef_var(a_batch_attack)\n",
    "        salcoef_iqr_bena += compute_coef_iqr(a_batch_attack)\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a18edb-06d3-4109-9a1f-691d58136221",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.hist(saliqr_ben, label='clean', color='blue')\n",
    "plt.hist(saliqr_bena, label='adv', alpha=0.7, color='red')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-2:429704687514:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
