{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9f6860c-c195-4b07-a288-e8148c35a8ac",
   "metadata": {},
   "source": [
    "## Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6116810f-1737-4632-ad1f-c2f9a109ff75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "!pip install â€“upgrade pip\n",
    "!pip install torch\n",
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install matplotlib\n",
    "!pip install torchvision\n",
    "!pip install opencv-python\n",
    "!pip install cv2\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53cd633f-1f43-437b-9bf2-ed77e81e8585",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "import seaborn as sns\n",
    "import random\n",
    "# import cv2\n",
    "import copy\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.utils import make_grid\n",
    "import torchvision.transforms as transform\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
    "from PIL import Image\n",
    "import gc\n",
    "\n",
    "# from mlxtend.plotting import plot_confusion_matrix\n",
    "# from sklearn.metrics import confusion_matrix\n",
    " \n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8d5e7c-c1db-4ff4-b51f-e877cc25c560",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1c090d2-e306-40d9-84c4-9ebc1cbc18dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = '../data/chest_xray/chest_xray'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85e86e01-5b4d-47a1-ba00-adb90d532e40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transformer = {\n",
    "    'dataset1': transform.Compose([transform.Resize(255),\n",
    "                                            transform.CenterCrop(224),\n",
    "                                            transform.RandomHorizontalFlip(),\n",
    "                                            transform.RandomRotation(10),\n",
    "                                            transform.RandomGrayscale(),\n",
    "                                            transform.RandomAffine(translate=(0.05,0.05), degrees=0),\n",
    "                                            transform.ToTensor()\n",
    "                                           ]),\n",
    "    \n",
    "    'dataset2' : transform.Compose([transform.Resize(255),\n",
    "                                            transform.CenterCrop(224),\n",
    "                                            transform.RandomHorizontalFlip(p=1),\n",
    "                                            transform.RandomGrayscale(),\n",
    "                                            transform.RandomAffine(translate=(0.1,0.05), degrees=10),\n",
    "                                            transform.ToTensor()\n",
    "                                    \n",
    "                                           ]),\n",
    "    'dataset3' : transform.Compose([transform.Resize(255),\n",
    "                                            transform.CenterCrop(224),\n",
    "                                            transform.RandomHorizontalFlip(p=0.5),\n",
    "                                            transform.RandomRotation(15),\n",
    "                                            transform.RandomGrayscale(p=1),\n",
    "                                            transform.RandomAffine(translate=(0.08,0.1), degrees=15),\n",
    "                                            transform.ToTensor()\n",
    "                                           ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab9f6bdc-5001-4dba-a31c-c7d5fc1ab6c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset1 = ImageFolder('data/chest_xray/chest_xray/train', \n",
    "                      transform=transformer['dataset1'])\n",
    "\n",
    "dataset2 = ImageFolder('data/chest_xray/chest_xray/train', \n",
    "                      transform=transformer['dataset2'])\n",
    "\n",
    "dataset3 = ImageFolder('data/chest_xray/chest_xray/train', \n",
    "                      transform=transformer['dataset3'])\n",
    "\n",
    "norm1, _ = train_test_split(dataset2, test_size= 3875/(1341+3875), shuffle=False)\n",
    "norm2, _ = train_test_split(dataset3, test_size= 4023/(1341+3875), shuffle=False)\n",
    "\n",
    "dataset = ConcatDataset([dataset1, norm1, norm2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89ecd000-dfc9-4c30-b586-02f02e995468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5425, 2325)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_seed = 2020\n",
    "torch.manual_seed(random_seed);\n",
    "train_ds, val_ds = train_test_split(dataset, test_size=0.3, random_state=random_seed)\n",
    "len(train_ds), len(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6fe5400d-0867-41b7-a43e-379cff92fa66",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=32\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_dl = DataLoader(val_ds, batch_size*2, num_workers=4, pin_memory=True)\n",
    "loaders = {'train':train_dl, 'val':val_dl}\n",
    "dataset_sizes = {'train':len(train_ds), 'val':len(val_ds)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8304d7f1-d670-40f6-82a7-abd9c5328dfc",
   "metadata": {},
   "source": [
    "## Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4bc37055-7824-4008-ab36-9e66f64c9a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1) \n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds)), preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68e2f525-cfd7-4826-8cef-5892b28cac51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet161_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet161_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = torchvision.models.densenet161(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "076f1359-9adc-4f2d-9000-84e2a51dc683",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "in_features = model.classifier.in_features\n",
    "\n",
    "model.classifier = nn.Linear(in_features, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "675f6665-a659-4242-b37c-aa43fe42d074",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = {'train':[], 'val':[]}\n",
    "accuracies = {'train':[], 'val':[]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa1baf4-a0c4-4d8b-bdb3-427c387d8c41",
   "metadata": {},
   "source": [
    "## Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55d4cdf8-0264-4cff-b2c7-c912fd03a389",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer, scheduler, epochs):\n",
    "    since = time.time()\n",
    "    best_model = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    for epoch in range(epochs):\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "      \n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0.0\n",
    "\n",
    "            for inputs, labels in loaders[phase]:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase=='train'):\n",
    "                    outp = model(inputs)\n",
    "                    _, pred = torch.max(outp, 1)\n",
    "                    loss = criterion(outp, labels)\n",
    "\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()*inputs.size(0)\n",
    "                running_corrects += torch.sum(pred == labels.data)\n",
    "\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double()/dataset_sizes[phase]\n",
    "            losses[phase].append(epoch_loss)\n",
    "            accuracies[phase].append(epoch_acc)\n",
    "            if phase == 'train':\n",
    "                print('Epoch: {}/{}'.format(epoch+1, epochs))\n",
    "                print('{} - loss:{}, accuracy{}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            if phase == 'val':\n",
    "                print('Time: {}m {}s'.format((time.time()- since)//60, (time.time()- since)%60))\n",
    "\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model = copy.deepcopy(model.state_dict())\n",
    "            scheduler.step()  \n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training Time {}m {}s'.format(time_elapsed//60, time_elapsed%60)) \n",
    "    print('Best accuracy {}'.format(best_acc))\n",
    "\n",
    "    model.load_state_dict(best_model)\n",
    "    return model   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "756a88aa-8635-4dbf-a49c-4938fcf1948e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.classifier.parameters(), lr = 0.001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 4, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de459723-5696-463c-92cb-1e01759c385e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10\n",
      "train - loss:0.28979414518253044, accuracy0.8980645161290323\n",
      "Time: 0.0m 53.59539771080017s\n",
      "Epoch: 2/10\n",
      "train - loss:0.1556787229133641, accuracy0.9458064516129032\n",
      "Time: 1.0m 44.75334119796753s\n",
      "Epoch: 3/10\n",
      "train - loss:0.13403330459298077, accuracy0.9570506912442396\n",
      "Time: 2.0m 36.02560257911682s\n",
      "Epoch: 4/10\n",
      "train - loss:0.1308433981864683, accuracy0.9574193548387097\n",
      "Time: 3.0m 27.671398162841797s\n",
      "Epoch: 5/10\n",
      "train - loss:0.1257433384794244, accuracy0.9592626728110599\n",
      "Time: 4.0m 19.707290410995483s\n",
      "Epoch: 6/10\n",
      "train - loss:0.12689806278674834, accuracy0.9601843317972351\n",
      "Time: 5.0m 12.58913540840149s\n",
      "Epoch: 7/10\n",
      "train - loss:0.11998993485204636, accuracy0.9627649769585254\n",
      "Time: 6.0m 7.648072242736816s\n",
      "Epoch: 8/10\n",
      "train - loss:0.1285171330826623, accuracy0.9587096774193549\n",
      "Time: 7.0m 4.79159688949585s\n",
      "Epoch: 9/10\n",
      "train - loss:0.12665707443441662, accuracy0.9579723502304147\n",
      "Time: 7.0m 58.32562255859375s\n",
      "Epoch: 10/10\n",
      "train - loss:0.12765679231162444, accuracy0.960552995391705\n",
      "Time: 8.0m 50.13514709472656s\n",
      "Training Time 8.0m 50.13578963279724s\n",
      "Best accuracy 0.956989247311828\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "epochs = 10\n",
    "model = train(model, criterion, optimizer, scheduler, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb8c4f3-dd6e-4594-ab76-8d1155ec889f",
   "metadata": {},
   "source": [
    "## Attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c807168a-ed37-4c3c-b918-7e8d6f70fee4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install captum\n",
    "!pip install cleverhans\n",
    "from captum.attr import IntegratedGradients\n",
    "from captum.attr import Saliency\n",
    "from captum.attr import DeepLift\n",
    "from captum.attr import NoiseTunnel\n",
    "from captum.attr import GradientShap\n",
    "from captum.attr import GuidedGradCam\n",
    "from captum.attr import LimeBase\n",
    "from captum.attr import KernelShap\n",
    "from captum.attr import Occlusion\n",
    "from captum.attr import visualization as viz\n",
    "from cleverhans.torch.attacks.fast_gradient_method import fast_gradient_method\n",
    "from cleverhans.torch.attacks.carlini_wagner_l2 import carlini_wagner_l2\n",
    "from cleverhans.torch.attacks.projected_gradient_descent import (\n",
    "    projected_gradient_descent\n",
    ")\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78b8ede-6b65-466c-9484-233b242679d3",
   "metadata": {},
   "source": [
    "## Statsitical Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4db5c20c-6dd3-44a4-9cbc-58e71a4eefc3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_mean_abs_dev(attr): \n",
    "    scores = []\n",
    "    for i in range(len(attr)):\n",
    "        a = attr[i].flatten()\n",
    "        avg = np.mean(a)\n",
    "        deviation = a - avg \n",
    "        absolute_deviation = np.abs(deviation)\n",
    "        result = np.mean(absolute_deviation)\n",
    "        scores.append(result)\n",
    "    return scores    \n",
    "def compute_median_abs_dev(attr): \n",
    "    scores = []\n",
    "    for i in range(len(attr)):\n",
    "        a = attr[i].flatten()\n",
    "        med = np.median(a)\n",
    "        deviation = a - med \n",
    "        abs_deviation = np.abs(deviation)\n",
    "        result = np.median(abs_deviation)\n",
    "        scores.append(result)\n",
    "    return scores \n",
    "def compute_iqr(attr):\n",
    "    #inter-quartile range\n",
    "    scores = []\n",
    "    for i in range(len(attr)):\n",
    "        a = attr[i].flatten()\n",
    "        score_75 = np.percentile(a, 75)\n",
    "        score_25 = np.percentile(a, 25)\n",
    "        score_qt = score_75 - score_25\n",
    "        scores.append(score_qt)\n",
    "    return scores\n",
    "    \n",
    "def compute_coef_var(attr):\n",
    "    scores = []\n",
    "    for i in range(len(attr)):\n",
    "        a = attr[i].flatten()\n",
    "        m = np.mean(a)\n",
    "        st = np.std(attr[i])\n",
    "        sc = m/st\n",
    "        scores.append(sc)\n",
    "    return scores\n",
    "\n",
    "def compute_coef_iqr(attr):\n",
    "    scores = []\n",
    "    for i in range(len(attr)):\n",
    "        a = attr[i].flatten()\n",
    "        score_75 = np.percentile(a, 75)\n",
    "        score_25 = np.percentile(a, 25)\n",
    "        score_qt = (score_75 - score_25)/(score_75 + score_25)\n",
    "        scores.append(score_qt)\n",
    "    return scores\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fa686e-cc71-4928-b357-0d8cbb648eb5",
   "metadata": {},
   "source": [
    "## FGSM & Integrated Gradient Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1100fe9a-b8f7-4dfd-8c1d-a0cf64a5cb70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "igmedianAbs_ben = []\n",
    "igmeanAbs_ben = []\n",
    "igiqr_ben = []\n",
    "igcoef_var_ben=[]\n",
    "igcoef_iqr_ben = []\n",
    "\n",
    "dataiter = iter(train_dl)\n",
    "for i in range(10):\n",
    "    images, labels = next(dataiter)\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "    for ind in range(32):\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        input1 = images[ind].unsqueeze(0)\n",
    "        x_logits = model(images)\n",
    "        ig = IntegratedGradients(model)\n",
    "        a_batch_benign = ig.attribute(input1, target=labels[ind]).sum(axis=1).cpu().detach().numpy()\n",
    "        igmedianAbs_ben += compute_mean_abs_dev(a_batch_benign)\n",
    "        igmeanAbs_ben += compute_median_abs_dev(a_batch_benign)\n",
    "        igiqr_ben += compute_iqr(a_batch_benign)\n",
    "        igcoef_var_ben += compute_coef_var(a_batch_benign)\n",
    "        igcoef_iqr_ben += compute_coef_iqr(a_batch_benign)\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a607dc7a-3788-460b-86be-1f6723fe3e5d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(igiqr_ben, label='clean', color='blue')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5533e5-38e7-4790-8d25-102de52b06f0",
   "metadata": {},
   "source": [
    "## Thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "58a12a10-2c2b-4328-890d-46c848d7855a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_fpr(ben, t1, t2): \n",
    "    TN=0\n",
    "    FN=0\n",
    "    FP = 0 \n",
    "    TP=0\n",
    "    \n",
    "    for value in ben: \n",
    "        if t1<=value<=t2:\n",
    "            TN += 1\n",
    "        else: \n",
    "            FP += 1\n",
    "    \n",
    "    return (FP/(FP+TN))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6b8283d7-3f12-4be8-9f51-1f9795943867",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_tpr(adv, t1, t2): \n",
    "    TN=0\n",
    "    FN=0\n",
    "    FP = 0 \n",
    "    TP=0\n",
    "    \n",
    "    for value in adv: \n",
    "        if t1>value or value>t2:\n",
    "            TP += 1\n",
    "        else: \n",
    "            FN += 1\n",
    "    \n",
    "    return (TP/(TP+FN))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b63707a7-f1e3-43cc-83ee-0a1ac2c69ab9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03793680511755103 0.22749751028113196\n",
      "0.9375\n",
      "---\n",
      "5.0\n",
      "---\n",
      "10.0\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "print(min(igiqr_ben), max(igiqr_ben))\n",
    "\n",
    "igt1=[0.0446,0.0556, 0.061]\n",
    "igt2=[0.25,0.25,0.25]\n",
    "for x, y in zip(igt1,igt2):\n",
    "    print(compute_fpr(igiqr_ben, x, y))\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b281a5-1bee-4be3-ba91-0b4d8e58f61f",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e874a5dd-8550-42a5-aa74-952b7c35172a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "igmedianAbs_bena = []\n",
    "igmeanAbs_bena = []\n",
    "igiqr_bena = []\n",
    "igcoef_var_bena=[]\n",
    "igcoef_iqr_bena = []\n",
    "\n",
    "dataiter = iter(val_dl)\n",
    "\n",
    "for i in range(5):\n",
    "    images, labels = next(dataiter)\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "    for ind in range(64):\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        input1 = images[ind].unsqueeze(0)\n",
    "        ig = IntegratedGradients(model)\n",
    "        torch.cuda.empty_cache()\n",
    "        images_pgd = fast_gradient_method(model, input1, 32/255, np.inf)\n",
    "        _, y_pred_pgd = model(input1).max(1)\n",
    "        a_batch_attack = ig.attribute(inputs=images_pgd, target=y_pred_pgd).sum(axis=1).cpu().detach().numpy()\n",
    "        igmeanAbs_bena += compute_mean_abs_dev(a_batch_attack)\n",
    "        igmedianAbs_bena += compute_median_abs_dev(a_batch_attack)\n",
    "        igiqr_bena += compute_iqr(a_batch_attack)\n",
    "        igcoef_var_bena += compute_coef_var(a_batch_attack)\n",
    "        igcoef_iqr_bena += compute_coef_iqr(a_batch_attack)\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "eb333a8f-1ec5-4c66-885b-779f6286b03a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[100.0, 100.0, 100.0]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpr = []\n",
    "tpr = []\n",
    "\n",
    "for x, y in zip(igt1,igt2):\n",
    "    fpr.append(compute_fpr(igiqr_ben, x, y))\n",
    "    tpr.append(compute_tpr(igiqr_bena, x, y))\n",
    "tpr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc72435-ea18-4d70-9618-8a0cb86dce23",
   "metadata": {},
   "source": [
    "## FGSM & Saliency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3c7aefe5-98c9-4a7e-bb38-f4a8951cf535",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "salmedianAbs_ben = []\n",
    "salmeanAbs_ben = []\n",
    "saliqr_ben = []\n",
    "salcoef_var_ben=[]\n",
    "salcoef_iqr_ben = []\n",
    "\n",
    "dataiter = iter(val_dl)\n",
    "\n",
    "for i in range(3):\n",
    "    images, labels = next(dataiter)\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "    for ind in range(64):\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        input1 = images[ind].unsqueeze(0)\n",
    "        ig = Saliency(model)\n",
    "        a_batch_benign = ig.attribute(input1, target=labels[ind]).sum(axis=1).cpu().detach().numpy()\n",
    "        salmeanAbs_ben += compute_mean_abs_dev(a_batch_benign)\n",
    "        salmedianAbs_ben += compute_median_abs_dev(a_batch_benign)\n",
    "        saliqr_ben += compute_iqr(a_batch_benign)\n",
    "        salcoef_var_ben += compute_coef_var(a_batch_benign)\n",
    "        salcoef_iqr_ben += compute_coef_iqr(a_batch_benign)\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "18127a1c-067b-4f25-a597-4eb7f7011e4d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5487848669290543 3.237593427300453\n",
      "1.0416666666666665\n",
      "---\n",
      "5.208333333333334\n",
      "---\n",
      "10.416666666666668\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "print(min(saliqr_ben), max(saliqr_ben))\n",
    "\n",
    "salt1=[0.58,0.79999,0.84]\n",
    "salt2=[3.3,3.3,3.3]\n",
    "for x, y in zip(salt1,salt2):\n",
    "    print(compute_fpr(saliqr_ben, x, y))\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "caf2c0f7-7370-4b0f-935f-4fbb53cf7e14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "salmedianAbs_bena = []\n",
    "salmeanAbs_bena = []\n",
    "saliqr_bena = []\n",
    "salcoef_var_bena=[]\n",
    "salcoef_iqr_bena = []\n",
    "\n",
    "dataiter = iter(val_dl)\n",
    "\n",
    "for i in range(3):\n",
    "    images, labels = next(dataiter)\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "    for ind in range(64):\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        input1 = images[ind].unsqueeze(0)\n",
    "        ig = Saliency(model)\n",
    "        images_pgd = fast_gradient_method(model, input1, 16/255, np.inf)\n",
    "        _, y_pred_pgd = model(input1).max(1)\n",
    "        a_batch_attack = ig.attribute(inputs=images_pgd, target=y_pred_pgd).sum(axis=1).cpu().detach().numpy()\n",
    "        salmeanAbs_bena += compute_mean_abs_dev(a_batch_attack)\n",
    "        salmedianAbs_bena += compute_median_abs_dev(a_batch_attack)\n",
    "        saliqr_bena += compute_iqr(a_batch_attack)\n",
    "        salcoef_var_bena += compute_coef_var(a_batch_attack)\n",
    "        salcoef_iqr_bena += compute_coef_iqr(a_batch_attack)\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "98fd6c17-2837-495c-bb7f-b2f6bd3136ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[100.0, 100.0, 100.0]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpr = []\n",
    "tpr = []\n",
    "\n",
    "for x, y in zip(salt1,salt2):\n",
    "    fpr.append(compute_fpr(saliqr_ben, x, y))\n",
    "    tpr.append(compute_tpr(saliqr_bena, x, y))\n",
    "tpr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c763ac-8ad2-4414-96e6-1ef16ea6acae",
   "metadata": {},
   "source": [
    "## FGSM & GraidentSHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f41e7c9d-b09e-4a72-8a3d-b96f653079ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19/890496051.py:38: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  sc = m/st\n",
      "/tmp/ipykernel_19/890496051.py:48: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  score_qt = (score_75 - score_25)/(score_75 + score_25)\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "dataiter = iter(val_dl)\n",
    "\n",
    "\n",
    "gradmedianAbs_ben = []\n",
    "gradmeanAbs_ben = []\n",
    "gradiqr_ben = []\n",
    "gradcoef_var_ben=[]\n",
    "gradcoef_iqr_ben = []\n",
    "\n",
    "\n",
    "for i in range(3):\n",
    "    images, labels = next(dataiter)\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "    for ind in range(64):\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        input1 = images[ind].unsqueeze(0)\n",
    "        x_logits = model(images)\n",
    "        ig = GradientShap(model)\n",
    "        rand_img_dist = torch.cat([input1 * 0, input1 * 1])\n",
    "        a_batch_benign = ig.attribute(input1, target=labels[ind],baselines=rand_img_dist).sum(axis=1).cpu().detach().numpy()\n",
    "        gradmeanAbs_ben += compute_mean_abs_dev(a_batch_benign)\n",
    "        gradmedianAbs_ben += compute_median_abs_dev(a_batch_benign)\n",
    "        gradiqr_ben += compute_iqr(a_batch_benign)\n",
    "        gradcoef_var_ben += compute_coef_var(a_batch_benign)\n",
    "        gradcoef_iqr_ben += compute_coef_iqr(a_batch_benign)\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "07fdb77f-a64e-4be5-9c12-91717a04a48c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.2095545306801796\n",
      "6.25\n",
      "---\n",
      "11.458333333333332\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "print(min(gradiqr_ben), max(gradiqr_ben))\n",
    "\n",
    "gradt1=[0.0001,0.03]\n",
    "gradt2=[0.25,0.25]\n",
    "for x, y in zip(gradt1,gradt2):\n",
    "    print(compute_fpr(gradiqr_ben, x, y))\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b3a126-78f9-4a82-97e0-e6cc64d254f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "dataiter = iter(val_dl)\n",
    "\n",
    "\n",
    "gradmedianAbs_bena = []\n",
    "gradmeanAbs_bena = []\n",
    "gradiqr_bena = []\n",
    "gradcoef_var_bena=[]\n",
    "gradcoef_iqr_bena = []\n",
    "\n",
    "\n",
    "for i in range(3):\n",
    "    images, labels = next(dataiter)\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "    \n",
    "    for ind in range(64):\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        input1 = images[ind].unsqueeze(0)\n",
    "        x_logits = model(input1).max(1)\n",
    "        ig = GradientShap(model)\n",
    "        rand_img_dist = torch.cat([input1 * 0, input1 * 1])\n",
    "        images_pgd = fast_gradient_method(model, input1, 64/255, np.inf)\n",
    "        _, y_pred_pgd = model(input1).max(1)\n",
    "        if y_pred_pgd != x_logits:\n",
    "            a_batch_attack = ig.attribute(images_pgd, target=y_pred_pgd,baselines=rand_img_dist).sum(axis=1).cpu().detach().numpy()\n",
    "            gradmeanAbs_bena += compute_mean_abs_dev(a_batch_attack)\n",
    "            gradmedianAbs_bena += compute_median_abs_dev(a_batch_attack)\n",
    "            gradiqr_bena += compute_iqr(a_batch_attack)\n",
    "            gradcoef_var_bena += compute_coef_var(a_batch_attack)\n",
    "            gradcoef_iqr_bena += compute_coef_iqr(a_batch_attack)\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bea8a6-e571-4baf-b697-1226e598047d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fpr = []\n",
    "tpr = []\n",
    "\n",
    "for x, y in zip(gradt1,gradt2):\n",
    "    fpr.append(compute_fpr(gradiqr_ben, x, y))\n",
    "    tpr.append(compute_tpr(gradiqr_bena, x, y))\n",
    "tpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b067d14e-143d-4cd7-9521-d40ffb07ec28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.hist(gradiqr_ben, label='clean', color='blue')\n",
    "plt.hist(gradiqr_bena, label='adv', alpha=0.7, color='red')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-2:429704687514:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
